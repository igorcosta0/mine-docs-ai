# Compara√ß√£o de Modelos LLM (Llama 3 vs Qwen 2.5)

## üìã Vis√£o Geral

Este projeto agora suporta m√∫ltiplos modelos LLM locais via Ollama, permitindo comparar a performance entre diferentes modelos durante o processamento do Data Lake.

## ü§ñ Modelos Dispon√≠veis

### 1. **Llama 3** (Meta)
- **Tamanho**: 4.7GB
- **Caracter√≠sticas**: R√°pido e eficiente, excelente para tarefas gerais
- **Ideal para**: Processamento r√°pido de documentos, an√°lises simples
- **Comando de instala√ß√£o**: `ollama pull llama3`

### 2. **Qwen 2.5 (14B)** (Alibaba)
- **Tamanho**: 9GB
- **Caracter√≠sticas**: Otimizado para tarefas complexas, racioc√≠nio avan√ßado
- **Ideal para**: An√°lises t√©cnicas profundas, extra√ß√£o de conhecimento especializado
- **Comando de instala√ß√£o**: `ollama pull qwen2.5:14b`

### 3. **Qwen 2.5 (7B)** (Alibaba)
- **Tamanho**: 4.7GB
- **Caracter√≠sticas**: Vers√£o menor e mais r√°pida do Qwen
- **Ideal para**: Balan√ßo entre velocidade e capacidade de an√°lise
- **Comando de instala√ß√£o**: `ollama pull qwen2.5:7b`

## üöÄ Como Usar

### Passo 1: Instalar os Modelos

Antes de usar, instale os modelos desejados via terminal:

```bash
# Instalar Llama 3
ollama pull llama3

# Instalar Qwen 2.5 (14B)
ollama pull qwen2.5:14b

# Instalar Qwen 2.5 (7B)
ollama pull qwen2.5:7b
```

### Passo 2: Ativar Modo Offline

1. Acesse o **Data Lake** ou o **Assistente IA**
2. Ative o switch **"Offline"** ou **"Offline (Ollama)"**
3. O seletor de modelo aparecer√° automaticamente

### Passo 3: Selecionar o Modelo

- No **Data Lake AI Assistant**: O seletor aparece abaixo do switch Offline
- No **Agent Dock** (assistente flutuante): Acesse as configura√ß√µes no rodap√©

### Passo 4: Executar An√°lises

Ap√≥s selecionar o modelo, todas as opera√ß√µes usar√£o o modelo escolhido:
- An√°lise Completa do Data Lake
- Processamento de documentos
- Consultas ao especialista IA
- Gera√ß√£o de expertise

## üìä Compara√ß√£o de Performance

### Visualiza√ß√£o Autom√°tica

A aba **"‚ö° Performance"** no Data Lake AI Assistant mostra:

- **Tempo M√©dio de Resposta**: Quanto tempo cada modelo leva para processar
- **Tokens por Segundo**: Velocidade de gera√ß√£o de texto
- **Taxa de Sucesso**: Confiabilidade de cada modelo
- **N√∫mero de Testes**: Quantidade de execu√ß√µes realizadas

### M√©tricas Capturadas Automaticamente

O sistema registra automaticamente:
- ‚úÖ Tempo de resposta (em segundos)
- ‚úÖ Velocidade de gera√ß√£o (tokens/segundo)
- ‚úÖ Taxa de sucesso vs falhas
- ‚úÖ Timestamp de cada execu√ß√£o

### Como Comparar

1. Execute a **An√°lise Completa** com o **Llama 3**
2. Note o tempo de processamento e resultados
3. Execute novamente com o **Qwen 2.5**
4. Acesse a aba **"‚ö° Performance"** para ver a compara√ß√£o

## üèÜ Qual Escolher?

### Escolha o Llama 3 se:
- ‚ö° Precisa de velocidade m√°xima
- üíª Tem recursos limitados de hardware
- üìÑ Est√° processando documentos simples
- üîÑ Precisa de alta taxa de processamento

### Escolha o Qwen 2.5 (14B) se:
- üß† Precisa de an√°lise t√©cnica profunda
- üìö Documentos s√£o muito especializados
- üéØ Qualidade √© mais importante que velocidade
- üí™ Tem recursos de hardware robustos (>16GB RAM)

### Escolha o Qwen 2.5 (7B) se:
- ‚öñÔ∏è Quer balan√ßo entre velocidade e qualidade
- üíª Recursos moderados de hardware
- üîÄ Documentos t√™m complexidade variada

## üí° Dicas de Performance

### Otimiza√ß√£o de Hardware

- **RAM Recomendada**: 
  - Llama 3: 8GB+
  - Qwen 7B: 8GB+
  - Qwen 14B: 16GB+

- **CPU**: Quanto mais cores, melhor o desempenho
- **GPU**: Ollama pode usar GPU se dispon√≠vel (acelera muito!)

### Processamento em Lote

O sistema j√° processa **5 documentos em paralelo** por padr√£o. Com modelos mais r√°pidos como Llama 3, voc√™ pode:
- Aumentar o lote no c√≥digo (`BATCH_SIZE = 10`)
- Processar mais documentos simultaneamente

### Cache e Reutiliza√ß√£o

O sistema **n√£o reprocessa** documentos j√° analisados, economizando tempo e recursos.

## üîß Configura√ß√£o Avan√ßada

### Testando Conex√£o

Use o bot√£o **"Testar Conex√£o"** em **Configura√ß√µes do Agente** para:
- ‚úÖ Verificar se o Ollama est√° rodando
- ‚úÖ Ver quantos modelos est√£o instalados
- ‚úÖ Validar conectividade

### Performance Tracking

As m√©tricas de performance s√£o salvas em mem√≥ria e limitadas a:
- **100 registros totais** (automaticamente limpa os mais antigos)
- **20 registros por modelo** para compara√ß√£o
- Atualiza√ß√£o em tempo real durante processamento

## üìà Benchmarks Esperados

### Processamento de 50 Documentos T√©cnicos

| Modelo | Tempo Total | Conhecimentos Extra√≠dos | Taxa Sucesso |
|--------|------------|------------------------|--------------|
| Llama 3 | ~8-12 min | 250-350 | 95-98% |
| Qwen 7B | ~10-15 min | 280-400 | 96-99% |
| Qwen 14B | ~15-20 min | 300-450 | 97-99% |

*Valores aproximados, variam com hardware e complexidade dos documentos*

## üêõ Solu√ß√£o de Problemas

### Modelo n√£o aparece na lista

```bash
# Verifique modelos instalados
ollama list

# Se n√£o estiver instalado
ollama pull [nome-do-modelo]
```

### Erro de conex√£o

```bash
# Verifique se Ollama est√° rodando
ollama serve

# Configure CORS se necess√°rio
export OLLAMA_ORIGINS=*
```

### Performance baixa

- Feche outros aplicativos pesados
- Verifique uso de RAM/CPU no gerenciador de tarefas
- Considere usar modelo menor (Llama 3 ou Qwen 7B)

## üéØ Casos de Uso Recomendados

### Desenvolvimento R√°pido
**Modelo**: Llama 3  
**Cen√°rio**: Testar o sistema, desenvolvimento iterativo

### Produ√ß√£o Balanceada
**Modelo**: Qwen 2.5 (7B)  
**Cen√°rio**: Uso di√°rio, documentos variados

### An√°lise Cr√≠tica
**Modelo**: Qwen 2.5 (14B)  
**Cen√°rio**: Projetos importantes, documentos complexos

## üìö Pr√≥ximos Passos

- Execute testes com ambos os modelos
- Compare os resultados na aba Performance
- Escolha o modelo que melhor atende suas necessidades
- Configure como padr√£o nas configura√ß√µes do agente
